# -*- coding: utf-8 -*-
"""3-1 최근접 이웃 회귀_2023312822 유선아

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XyILA_nAQsNZt2Ut2fHrrqi0ZJad0Izq

# k-최근접 이웃 회귀

<table align="left">
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/3-1.ipynb"><img src="https://www.tensorflow.org/images/colab_logo_32px.png" />구글 코랩에서 실행하기</a>
  </td>
</table>

## 데이터 준비
"""

import numpy as np

perch_length = np.array(
    [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0,
     21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5,
     22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5,
     27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0,
     36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0,
     40.0, 42.0, 43.0, 43.0, 43.5, 44.0]
     )
# 넘파이 배열의 농어 길이

perch_weight = np.array(
    [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0,
     110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0,
     130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0,
     197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0,
     514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0,
     820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0,
     1000.0, 1000.0]
     )
# 넘파이 배열의 농어 무게

import matplotlib.pyplot as plt

plt.scatter(perch_length, perch_weight)
# 농어 길이와 무게를 산점도로 표현

plt.xlabel('length')
plt.ylabel('weight')
plt.show()
# 농어의 길이가 커짐에 따라 무게도 늘어남을 알 수 있음

from sklearn.model_selection import train_test_split
# 훈련 세트와 테스트 세트 나누기 위해 train_test_split 사용

train_input, test_input, train_target, test_target = train_test_split(
    perch_length, perch_weight, random_state=42)
# train_test_split() 함수로 훈련 세트와 테스트 세트로 나눔
# 동일한 결과 유지를 위해 random_state(랜덤시드와 같은 역할, 임의의 수) 일정하게 지정

print(train_input.shape, test_input.shape)
# train_input과 test_input shape 출력
# 1차원 데이터는 오류가 나므로 2dim(2차원) 데이터로 만들어야

test_array = np.array([1,2,3,4])
print(test_array.shape)
# test_array shape 출력
# 원본 배열의 원소의 개수는 4개

test_array = test_array.reshape(2, 2)
print(test_array.shape)
# reshape으로 (2,2) 크기가 나오도록 설정

# test_array = test_array.reshape(2, 3)
# 2X3=6개의 원소 -> 원본과 원소의 개수가 다르므로 에러 발생

train_input = train_input.reshape(-1, 1)
test_input = test_input.reshape(-1, 1)
# reshape(-1,1)을 통해 두번째 크기를 1로 설정하고, -1로 설정된 곳은 나머지 원소 개수로 채움 <- 데이터가 많아서 크기 모를 때 유용

print(train_input.shape, test_input.shape)
# reshape된 train_input, test_input shape 출력

"""## 결정 계수 ($ R^2$)"""

from sklearn.neighbors import KNeighborsRegressor
# KNeighborsRegressor : 사이킷런에서 k-최근접 이웃 회귀 알고리즘을 구현하는 클래스

knr = KNeighborsRegressor()
knr.fit(train_input, train_target)
# k-최근접 이웃 회귀 모델 훈련

knr.score(test_input, test_target)
# score() 성능 평가
# 결정계수(R^2)로 회귀 결과 평가 : 1-((타킷-예측)^2의 합)/((타깃-평균)^2의 합) => 평균정도를 예측하는 수준이라면 0에 가까운 값, 예측이 타킷에 아주 가까워지면 1에 가까운 값

from sklearn.metrics import mean_absolute_error
# mean_absolute_error : 타깃과 예측의 절댓값 오차를 평균하여 반환(MAE) <- 회귀 알고리즘 평가 척도(MSE, RMSE, MAE)

test_prediction = knr.predict(test_input)
# 테스트 세트에 대한 예측

mae = mean_absolute_error(test_target, test_prediction)
# 테스트 세트에 평균 절댓값 오차 평균 계산

print(mae)
# mae 출력

"""## 과대적합 vs 과소적합

- 훈련 세트 >> 테스트 세트 : 모델이 훈련 세트에 과대적합(Overfitting)
- 훈련 세트 << 테스트 세트 or 두 점수 모두 낮은 경우 : 모델이 훈련 세트에 과소적합(Underfitting)
"""

print(knr.score(train_input, train_target))
# 훈련 세트(0.96)보다 테스트 세트(0.99)의 점수 높다 => 과소적합
# data 개수가 적어서 과소적합 발생했다고 생각 => 모델을 조금 더 복잡하게 만든다

knr.n_neighbors = 3
# 이웃의 개수를 3으로 설정 (defalut=5)

# 이웃의 개수 k를 줄이면, 훈련 세트에 있는 국지적인 패턴에 민감해지고 복잡해짐
# 이웃의 개수 k를 늘리면, 데이터 전반에 있는 일반적인 패턴을 따름

knr.fit(train_input, train_target)
# 모델 훈련

print(knr.score(train_input, train_target))
# 훈련 세트 성능 평가(결정계수 R^2)

print(knr.score(test_input, test_target))
# 테스트 세트 성능 평가
# 테스트 세트(0.97)<훈련 세트(0.98) => 해결

"""## 확인문제"""

# k-최근접 이웃 회귀 객체를 만듭니다
knr = KNeighborsRegressor()
# 5에서 45까지 x 좌표를 만듭니다
x = np.arange(5, 45).reshape(-1, 1)

# n = 1, 5, 10일 때 예측 결과를 그래프로 그립니다.
for n in [1, 5, 10]:
    # 모델 훈련
    knr.n_neighbors = n
    knr.fit(train_input, train_target)
    # 지정한 범위 x에 대한 예측 구하기
    prediction = knr.predict(x)
    # 훈련 세트와 예측 결과 그래프 그리기
    plt.scatter(train_input, train_target)
    plt.plot(x, prediction)
    plt.title('n_neighbors = {}'.format(n))
    plt.xlabel('length')
    plt.ylabel('weight')
    plt.show()